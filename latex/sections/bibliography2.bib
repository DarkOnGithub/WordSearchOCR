% --- OPTIMIZERS ---

% AdamW
@inproceedings{loshchilov2017decoupled,
  title={Decoupled Weight Decay Regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019},
  url={https://arxiv.org/abs/1711.05101}
}

% --- ARCHITECTURES & CONVOLUTIONS ---

% The "CNN Paper" (LeNet-5)
@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={IEEE}
}

% Winograd Convolution
@inproceedings{lavin2016fast,
  title={Fast Algorithms for Convolutional Neural Networks},
  author={Lavin, Andrew and Gray, Scott},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={4013--4021},
  year={2016}
}

% im2col + GEMM
% (Chellapilla is widely cited for popularizing the unrolling technique for GPUs)
@inproceedings{chellapilla2006high,
  title={High performance convolutional neural networks for document processing},
  author={Chellapilla, Kumar and Puri, Sidd and Simard, Patrice},
  booktitle={Tenth International Workshop on Frontiers in Handwriting Recognition},
  year={2006},
  organization={Suvisoft}
}

% --- INITIALIZATION ---

% Xavier / Glorot Initialization
@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

% Kaiming / He Initialization
@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on {ImageNet} classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}

% --- LAYERS & ACTIVATIONS ---

% Batch Normalization
@inproceedings{ioffe2015batch,
  title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={448--456},
  year={2015}
}

% SiLU (Sigmoid Weighted Linear Units)
% Note: This is the specific SiLU paper. The function is also known as "Swish" (Ramachandran et al. 2017).
@inproceedings{elfwing2018sigmoid,
  title={Sigmoid-weighted linear units for neural network function approximation in reinforcement learning},
  author={Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  booktitle={Neural Networks},
  volume={107},
  pages={3--11},
  year={2018},
  publisher={Elsevier}
}